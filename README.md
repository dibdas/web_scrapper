
# Web Scraping using Nokogiri 

<h2 align="center">Microverse-Ruby-Capstone-Project</h2>

## Definition of Web Scraping

Web scraping, web harvesting, or web data extraction is data scraping used for extracting data from websites. Web scraping software may access the World Wide Web directly using the Hypertext Transfer Protocol, or through a web browser. While web scraping can be done manually by a software user, the term typically refers to automated processes implemented using a bot or web crawler.
## Techniques

Web scraping is the process of automatically mining data or collecting information from the World Wide Web. It is a field with active developments sharing a common goal with the semantic web vision, an ambitious initiative that still requires breakthroughs in text processing, semantic understanding, artificial intelligence and human-computer interactions. Current web scraping solutions range from the ad-hoc, requiring human effort, to fully automated systems that are able to convert entire web sites into structured information, with limitations.

## About Project

The purpose of this project is to develop a scraper tool to achieve web-scrapping. This was achieved using Ruby,Nokogiri gem. The coursera page uses the production build of React which made the project more interesting to build.


- Nokogiri is an HTML, XML, SAX, and Reader parser. Among Nokogiri's many features is the ability to search documents via XPath or CSS3 selectors.

- The above Ruby Gems can be sources from [Ruby Gems](https://rubygems.org/)

In this project, I created a scraper which extracts free coursera courses from the [weworkremotely](https://weworkremotely.com/).

# Built With
 - Nokogiri 
 - RSpec 
 - Rubocop 
 - Ruby 
 


 # Getting Started

To get started, you should first get this file in your local machine by downloading this project or typing.
`
git 
`
## Prerequisites

    Ruby installed on local machine
    Text editor (preferably: VSCode, Atom)
    Git

## Setup

   If you have installed `Ruby` on your machine:

   1. Clone the project into your local machine using `git clone` command or download the zip file.
   2. Go into the project directory using `cd directory name` command.
   3. Install required gems by using `bundle install`
   4. From the root directory type `ruby bin/main.rb` command.
## Running the scraper

    When you run the project it will show you the jobs in the terminal available on the selected page ui..
    In the specified jobs available you desire you can see the name of the company, role and the remote location.

# Contributing

:handshake: Contributions, issues and feature requests are welcome!
Start by:

    1. Forking the project
    2. Cloning the project to your local machine
    3. cd into the project directory
    4. Run git checkout -b your-branch-name
    5. Make your contributions
    6. Push your branch up to your forked repository
    7. Open a Pull Request with a detailed description to the development branch of the original project for a review

Please feel free to contribute to any of these!

Feel free to check the [issues page](https://github.com/dibdas/web_scrapper/issues).

## Author

üë§ **Dibyendu Das**

- GitHub: [@DibDas](https://github.com/dibdas)
- Twitter: [@DIBYEND78120480](https://twitter.com/DIBYEND78120480)
- LinkedIn: [Dibyendu Das](https://www.linkedin.com/in/dibyendu-das-b5967a1b1/)


# üìù License

This project is [MIT]() licensed.

Happy coding!
